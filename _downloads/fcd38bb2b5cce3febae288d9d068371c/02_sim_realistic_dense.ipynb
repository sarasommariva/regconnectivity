{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Part 3: Generate sensor level recordings and compute optimal parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path as op\nimport os\nimport numpy as np\nimport math\nimport sys\nimport time\nimport datetime\nfrom scipy import optimize, signal\nfrom mne import (read_forward_solution, convert_forward_solution,\n                 pick_types_forward)\nimport functions_code as myf\ntarget = '.'\nnoct = '6'\nt_init = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "load data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# data path\nfile_fwd = op.join(target, 'data', 'oct'+noct+'_fwd.fif')\n\n# load fwd\nfwd = read_forward_solution(file_fwd, verbose=False)\nfwd = convert_forward_solution(\n    fwd, surf_ori=True, force_fixed=True, use_cps=True, verbose=False)\nfwd = pick_types_forward(fwd, meg='mag', eeg=False, ref_meg=False)\n\n# leadfield matrix\nG = fwd['sol']['data']\nG = 10**5*G  # rescale to avoid small numbers\nGGt = G.dot(G.T)\n\n\nsys.stdout.flush()\n\n# dipols position\ndip_pos = fwd['source_rr']\n\n# dipols orientations\ndip_or = fwd['source_nn']\n\n# load cortico-cortical distance matrix\ncortico_dist_file = op.join(target, 'data', 'cortico_dist_oct'+noct+'.npy')\ncortico_dist = np.load(cortico_dist_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load seeds time courses and locations\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "seed_tc_loc = np.load('./run_data/seed_tc_loc.npy', allow_pickle='TRUE').item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "define features of the simulation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "features = seed_tc_loc['features']\nseed_tcs = seed_tc_loc['seed_tcs']\nseed_locs = seed_tc_loc['seed_locs']\nN_mod = int(sys.argv[1])  # Number of simulated AR models (with connections)\nN_act = features['N_act']\nN_loc = int(sys.argv[2])  # Number of different connected pairs of locations\nT = features['T']\nfs = features['fs']\nfmin = features['fmin']\nfmax = features['fmax']\n# radius of the patch (maximum distance from the seed in meters)\npatch_radii = np.sqrt((np.array([2, 4, 8])*10**(-4))/math.pi)\ncoh_levels = np.array([1, 0.5, 0.2])  # intra coherence levels\nbg_noise_levels = np.array([0.1, 0.5, 0.9])  # intensity of background noise\nN_snr = int(4)  # Number of snr levels\nSNR_val = np.linspace(-20, 5, N_snr)  # SNR values\nM = G.shape[0]  # Number of sensor\nN_dense = G.shape[1]  # Number of sources in the dense source space\n\n# store newly defined features\nfeatures['patch_radii'] = patch_radii\nfeatures['coh_levels'] = coh_levels\nfeatures['bg_noise_levels'] = bg_noise_levels\nfeatures['SNR_val'] = SNR_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "simulate sensor level data and compute optimal parameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "job_run = int(sys.argv[3]) - 1\ni_mod = job_run % N_mod\ni_loc = job_run//N_mod\nprint('i_mod='+str(i_mod))\nprint('i_loc='+str(i_loc))\nsys.stdout.flush()\nseed_loc = seed_locs[i_loc, :]\nseed_tc = seed_tcs[:, :, i_mod]\nlambdas = np.logspace(-5, 1, num=15)\n\n# initialize dictionary to store the parameters\nparameters = {'tc': np.zeros((len(patch_radii), len(coh_levels),\n                              len(bg_noise_levels), N_snr, 4)),\n              'tc_AUC': np.zeros((len(patch_radii), len(coh_levels),\n                                  len(bg_noise_levels), N_snr, 2, len(lambdas))),\n              'conn': np.zeros((len(patch_radii), len(coh_levels),\n                                len(bg_noise_levels), N_snr, 4, len(lambdas))),\n              'TPF_conn': np.zeros((len(patch_radii), len(coh_levels),\n                                    len(bg_noise_levels), N_snr, len(lambdas),\n                                    4, 20)),\n              'FPF_conn': np.zeros((len(patch_radii), len(coh_levels),\n                                    len(bg_noise_levels), N_snr, len(lambdas),\n                                    4, 20)),\n              'sigma_noise': np.zeros((len(patch_radii), len(coh_levels),\n                                       len(bg_noise_levels), N_snr))}\n\n# initialize matrix to store spectral complecxity levels\nspectal_complexity_Y = np.zeros(\n    (len(patch_radii), len(coh_levels), len(bg_noise_levels), N_snr))\n\nnperseg = 256\nnfft = nperseg\nP = 5\n\nfor r in patch_radii:\n    i_r = np.where(patch_radii == r)[0][0]\n    # define patches given the seeds and the radius\n    print('generating patches')\n    sys.stdout.flush()\n    p1_locs, p2_locs = myf.gen_patches_sources(cortico_dist, r, seed_loc)\n\n    for c in coh_levels:\n        i_c = np.where(coh_levels == c)[0][0]\n\n        # generate coherent patches\n        print('generating patch tcs')\n        sys.stdout.flush()\n        tic = time.time()\n        p1_tcs, p2_tcs = myf.gen_coherent_patches(\n            seed_tc, p1_locs, p2_locs, c, i_c, nperseg, nfft, fs, fmin, fmax)\n        toc = time.time()\n        print('time for generating coherent patches:'+str(toc-tic))\n        sys.stdout.flush()\n\n        # generate background activity\n        print('generating background tcs')\n        sys.stdout.flush()\n        tic = time.time()\n        bg_locs = np.setdiff1d(\n            np.arange(N_dense), np.concatenate((p1_locs, p2_locs)))\n        bg_tcs_general = myf.gen_background_tcs(P, len(bg_locs), T)\n        toc = time.time()\n        print('time for generating background tcs:'+str(toc-tic))\n        sys.stdout.flush()\n\n        # define the norm of patches and background activity to define the snr\n        # between patches and bg\n        patches_norm = np.linalg.norm(np.concatenate(\n            (p1_tcs, p2_tcs), axis=0), ord='fro')**2\n        bg_norm_general = np.linalg.norm(bg_tcs_general, ord='fro')**2\n\n        for Gamma in bg_noise_levels:\n            i_gamma = np.where(bg_noise_levels == Gamma)[0][0]\n\n            # scale bg activity to the desired level of Gamma\n            bg_tcs = bg_tcs_general * \\\n                np.sqrt((patches_norm/bg_norm_general)*Gamma)\n\n            # define brain activity\n            X = np.zeros((N_dense, T))\n            X[bg_locs, :] = bg_tcs\n            X[p1_locs, :] = p1_tcs\n            X[p2_locs, :] = p2_tcs\n            for Alpha in SNR_val:\n                i_snr = np.where(SNR_val == Alpha)[0][0]\n\n                # generate sensor level noise\n                N_tilde = np.random.randn(M, T)\n                Sigma = np.sqrt(np.linalg.norm(G.dot(X), ord='fro')**2 /\n                                (10**(Alpha/10)*np.linalg.norm(N_tilde, ord='fro')**2))\n                N = Sigma*N_tilde\n                parameters['sigma_noise'][i_r, i_c, i_gamma, i_snr] = Sigma\n\n                # define sensor data\n                Y = G.dot(X)+N\n\n                spectal_complexity_Y[i_r, i_c, i_gamma, i_snr] = myf.spectral_complexity(\n                    Y, fs, nperseg, fmin, fmax)\n\n                # define the matrix of positives and negatives (positives=1,\n                # negtives=0) for neural activity\n                PN_matrix_tc = np.zeros((N_dense, ), dtype=int)\n                PN_matrix_tc[p1_locs] = np.ones((len(p1_locs), ), dtype=int)\n                PN_matrix_tc[p2_locs] = np.ones((len(p2_locs), ), dtype=int)\n\n                # define the matrix of positives and negatives (positives=1,\n                # negtives=0) for connectivity\n                PN_matrix_conn = np.zeros((len(p1_locs), N_dense), dtype=int)\n                PN_matrix_conn[:, p2_locs] = np.ones(\n                    (len(p1_locs), len(p2_locs)), dtype=int)\n                PN_matrix_conn = np.delete(PN_matrix_conn, p1_locs, axis=-1)\n\n                # COMPUTE REGULARIZATION PARAMETERS\n\n                tic = time.time()\n                sys.stdout.flush()\n                b, a = signal.butter(3, np.array(\n                    [8, 12]), btype='bandpass', analog=False, output='ba', fs=fs)\n                X_filt = signal.filtfilt(b, a, X, axis=- 1, padtype='odd',\n                                         padlen=None, method='pad', irlen=None)\n                Y_filt = signal.filtfilt(b, a, Y, axis=- 1, padtype='odd',\n                                         padlen=None, method='pad', irlen=None)\n                input_lamX = np.linalg.norm(\n                    N, ord='fro')**2/np.linalg.norm(G.dot(X), ord='fro')**2\n\n                print('computing lam X')\n                # lambda X\n                opt_set = optimize.minimize(myf.err_X, input_lamX, args=(\n                    X, Y, G, GGt), method='Nelder-Mead')\n                lamX = opt_set['x'][0].copy()\n\n                # lambda X alpha range\n                opt_set = optimize.minimize(myf.err_X, input_lamX, args=(\n                    X_filt, Y_filt, G, GGt), method='Nelder-Mead')\n                lamX_alpha = opt_set['x'][0].copy()\n\n                toc = time.time()\n                print('time for computing lamX:'+str(toc-tic))\n                sys.stdout.flush()\n\n                # lambda connectivity\n                print('computing optimal parameters for connectivity')\n                tic = time.time()\n                sys.stdout.flush()\n\n                # TPF, dimension: lambdas*conn_meths*thresholds\n                TPF_conn = np.zeros((len(lambdas), 4, 20))\n                # FPF, dimension: lambdas*conn_meths*thresholds\n                FPF_conn = np.zeros((len(lambdas), 4, 20))\n                AUC_conn = np.zeros((len(lambdas), 4))\n                for i_lam in range(len(lambdas)):\n                    AUC_conn[i_lam, :], TPF_conn[i_lam, :, :], FPF_conn[i_lam, :, :], = myf.auc(\n                        lambdas[i_lam]*lamX, ['cpsd', 'imcoh', 'ciplv', 'wpli'], G, GGt, Y,\n                        p1_locs, p2_locs, fmin, fmax, PN_matrix_conn, fs, nperseg)\n\n                parameters['tc'][i_r, i_c, i_gamma, i_snr, 0] = lamX.copy()\n                parameters['tc'][i_r, i_c, i_gamma,\n                                 i_snr, 1] = lamX_alpha.copy()\n                parameters['conn'][i_r, i_c, i_gamma,\n                                   i_snr, 0, :] = AUC_conn[:, 0].copy()\n                parameters['conn'][i_r, i_c, i_gamma,\n                                   i_snr, 1, :] = AUC_conn[:, 1].copy()\n                parameters['conn'][i_r, i_c, i_gamma,\n                                   i_snr, 2, :] = AUC_conn[:, 2].copy()\n                parameters['conn'][i_r, i_c, i_gamma,\n                                   i_snr, 3, :] = AUC_conn[:, 3].copy()\n                parameters['TPF_conn'][i_r, i_c, i_gamma,\n                                       i_snr, :, :, :] = TPF_conn.copy()\n                parameters['FPF_conn'][i_r, i_c, i_gamma,\n                                       i_snr, :, :, :] = FPF_conn.copy()\n\n                toc = time.time()\n                print(\n                    'time for computing optimal parameters for connectivity:'+str(toc-tic))\n                print(str(i_r), str(i_c), str(i_gamma), str(i_snr))\n                sys.stdout.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "simulate sensor level data and compute optimal parameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if not op.isdir('./run_data/'+str(job_run+1)):\n    os.makedirs('./run_data/'+str(job_run+1))\n\nnp.save('./run_data/'+str(job_run+1)+'/opt_parameters_loc'+str(i_loc) +\n        '_mod'+str(i_mod)+'_i_run'+str(job_run+1)+'.npy', parameters)\nnp.save('./run_data/'+str(job_run+1)+'/spectal_complexity_Y_loc'+str(i_loc) +\n        '_mod'+str(i_mod)+'_i_run'+str(job_run+1)+'.npy', spectal_complexity_Y)\nif (i_loc == 0 & i_mod == 0):\n    np.save('./run_data/tested_parameters.npy', lambdas)\n    np.save('./run_data/features.npy', features)\n\nprint('total run time: ' + str(datetime.timedelta(seconds=time.time()-t_init)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}