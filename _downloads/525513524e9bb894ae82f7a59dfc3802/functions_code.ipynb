{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Main functions\n\nFunctions used in files 01_generate_seed_tc.py and 02_sim_realistic_dense.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n# coding: utf-8\n\n\nimport numpy as np\nimport mne\nfrom scipy import signal\nfrom scipy.fft import fft, ifft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def select_sources(G, src, N_loc):\n    \"\"\"\n    Select N_loc pairs of active sources, given the leadfield (G) and the\n    source locations (src), so that the distance between the two sources is\n    grater than 4 cm (0.04 m) and the intensity at sensor level is similar\n    (i.e. the ratio of the norm of the corresponding leadfield columns is in\n    (9/10, 10/9))\n\n    Parameters:\n        G: array, shape (N_sensors, N_sources)\n            leadfeld matrix\n        src: array, shape (N_sources, 3)\n            sources locations in the source space\n        N_loc: int\n            number of pairs of sources\n\n    Returns:\n        sample: array, shape (N_loc, 2)\n            index of the selected sources in the source space\n    \"\"\"\n    sample = np.array([[int(0)]*2]*N_loc)\n    for k in range(N_loc):\n        ratio = np.inf\n        d = 0\n        while ratio < 9/10 or ratio > 10/9 or d < 0.04:\n            sample[k] = np.random.permutation(G.shape[1])[0:2]\n            norm1 = np.linalg.norm(np.transpose(G)[sample[k, 0]])\n            norm2 = np.linalg.norm(np.transpose(G)[sample[k, 1]])\n            ratio = norm1/norm2\n            d = np.linalg.norm(src[sample[k, 0]]-src[sample[k, 1]])\n    return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def gen_ar_model(N_act, P, Sigma):\n    \"\"\"\n    Generate an MVAR model with directional coupling from source 1 to source 2,\n    the third source, if present, is uncorrelated to the the first two\n\n    Parameters:\n        N_act: 2, 3\n            dimension of the model (i.e. number of time courses to be simulated)\n        P: int\n            order of the model\n        Sigma: float (in (0.1, 1))\n            variance of the non zero entries of the model\n\n    Returns:\n        model: dictionary\n            Dictionary containing:\\n\n                * the matrices that define the model\n                * N_act\n                * P\n    \"\"\"\n\n    lambdamax = 10\n    I = np.eye(N_act)\n    vect = (np.array([int(1)]), np.array([int(0)]))\n    index = np.where(I == 1)\n    vect = (np.concatenate((vect[0], index[0])),\n            np.concatenate((vect[1], index[1])))\n    while lambdamax < 0.9 or lambdamax >= 1:\n        Arsig = np.array([[], []])\n        for k in range(P):\n            aloc = np.zeros([N_act, N_act])\n            for s in range(vect[0].shape[0]):\n                aloc[vect[0][s], vect[1][s]] = np.random.randn(1)[0]*Sigma\n            Arsig = np.concatenate((Arsig, aloc), axis=1)\n        E = np.eye(N_act*P)\n        AA = np.concatenate((Arsig, E[0:-N_act, :]))\n        Lambda = np.linalg.eig(AA)[0]\n        lambdamax = max(abs(Lambda))\n    model = {'Arsig': Arsig, 'N_act': N_act, 'P': P}\n    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def gen_ar_series(AR_mod, T):\n    \"\"\"\n    Generate an MVAR time courses\n\n    Parameters:\n        AR_mod: dictionary (output of gen_AR_model)\n            Dictionary containing:\\n\n                * the matrices that define the model\n                * N_act\n                * P\n        T: int\n            number of time points of the generated time courses\n\n\n    Returns:\n        X: array, shape (N_act, T)\n            the generated time courses\n        AR_mod: dictionary\n            Dictionary containing:\\n\n                * the matrices that define the model\n                * N_act\n                * P\n    \"\"\"\n    Sigma = 1\n    N0 = 1000\n    N_act = AR_mod['N_act']\n    P = AR_mod['P']\n    Arsig = AR_mod['Arsig']\n    x = np.random.randn(N_act, T+N0)*Sigma\n    AR_mod['noise'] = x[:, P:].copy()\n    y = x.copy()\n    for k in range(P, T+N0):\n        yloc = np.concatenate(np.flip(y[:, k-P:k], axis=1).T, axis=None)\n        y[:, k] = Arsig.dot(yloc) + x[:, k]\n    X = y[:, N0:].copy()\n    return X, AR_mod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def gen_background_tcs(P, N_bg, T):\n    \"\"\"\n    Generate background noise time courses following univariate AR models\n\n    Parameters:\n        P: int\n            order of the AR model\n        N_bg: int\n            number of time coursed to generate\n        T: int\n            number of time points of the generate time courses\n\n    Returns:\n        bg_tcs: array, shape (N_bg, T)\n            the generated time courses\n    \"\"\"\n    bg_tcs = np.zeros((N_bg, T))\n    for i_bg in range(N_bg):\n\n        # genarate the model\n        lambdamax = 10\n        while lambdamax < 0.9 or lambdamax >= 1:\n            Arsig = np.zeros([1, 0])\n            for k in range(P):\n                aloc = np.random.randn(1, 1)\n                Arsig = np.concatenate((Arsig, aloc), axis=1)\n            E = np.eye(P)\n            AA = np.concatenate((Arsig, E[0:-1, :]))\n            Lambda = np.linalg.eig(AA)[0]\n            lambdamax = max(abs(Lambda))\n        # simulate tc\n        Sigma = 1\n        N0 = 1000\n        x = np.random.randn(1, T+N0)*Sigma\n        y = x.copy()\n        for k in range(P, T+N0):\n            yloc = np.concatenate(np.flip(y[:, k-P:k], axis=1).T, axis=None)\n            y[:, k] = Arsig.dot(yloc) + x[:, k]\n        bg_tcs[i_bg, :] = y[:, N0:].copy()\n\n    return bg_tcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def gen_patches_sources(cortico_dist, patch_radius, seed_loc):\n    \"\"\"\n    Define sources composing a patch with specific dirtance from the center\n\n    Parameters:\n        cortico_dist: array, shape (N_source, N_source\n            cortico distances between each pair of sources in the source space\n        patch_radius: float\n            radius of the patch\n        seed_loc: array, touple, list, shape (2, )\n            index of the seed sources\n\n    Returns:\n        p1_locs: array, shape (N_p1, )\n            the index of the sutces within the first patch\n        p1_locs: array, shape (N_p2, )\n            the index of the sutces within the second patch\n    \"\"\"\n    tmp_id_0 = np.argsort(cortico_dist[:, seed_loc[0]])\n    n_sources_0 = len(np.where(cortico_dist[:, seed_loc[0]] < patch_radius)[0])\n    tmp_id_1 = np.argsort(cortico_dist[:, seed_loc[1]])\n    n_sources_1 = len(np.where(cortico_dist[:, seed_loc[1]] < patch_radius)[0])\n\n    p1_locs = tmp_id_0[0:n_sources_0]\n    p2_locs = tmp_id_1[0:n_sources_1]\n    return p1_locs, p2_locs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def gen_coherent_patches(seed_tc, p1_locs, p2_locs, c, i_c, nperseg, nfft, fs, fmin, fmax):\n    \"\"\"\n    Generate time courses to be assigned to the sources within the patches.\n    The patches are Gaussian and have specific intracoherence level\n\n    Parameters:\n        seed_tc: array, shape (2, T)\n            time courses of the seeds of each patch\n        p1_locs: array, shpae (N_p1)\n            indeces of the sources within patch 1\n        p2_locs: array, shpae (N_p2)\n            indeces of the sources within patch 2\n        c: 1, 0.5, 2\n            coeherence level\n        i_c: not used anymore\n        nperseg: int\n            lenght of the epochs for the computation of the coherence\n        nfft: int\n            number of frequencies\n        fs: float\n            sampling frequency\n        fmin: float\n            minimum frequency for the computation of coherence\n        fmax: float\n            maximum frequency for the computation of coherence\n\n    Returns:\n        p1_tcs: array, shape (N_p1, T)\n            time courses of the sources in patch 1\n        p2_tcs: array, shape (N_p2, T)\n            time courses of the sources in patch 2\n    \"\"\"\n\n    # define gaussian window\n    # standard deviation patch 1\n    std_dev1 = (len(p1_locs)-1)/(np.sqrt(-2*np.log(0.4)))\n    w1 = signal.gaussian(len(p1_locs)*2-1, std_dev1)  # weights patch 1\n    w1 = w1[(len(p1_locs)-1):]\n    # standard deviation patch 2\n    std_dev2 = (len(p2_locs)-1)/(np.sqrt(-2*np.log(0.4)))\n    w2 = signal.gaussian(len(p2_locs)*2-1, std_dev2)  # weights patch 1\n    w2 = w2[(len(p2_locs)-1):]\n\n    T = seed_tc.shape[1]\n    if c == 1:\n        p1_tcs = np.tile(seed_tc[0, :].reshape((1, -1)), [len(p1_locs), 1])\n        p2_tcs = np.tile(seed_tc[1, :].reshape((1, -1)), [len(p2_locs), 1])\n    else:\n        p1_tcs = seed_tc[0, :].reshape((1, -1))\n        p2_tcs = seed_tc[1, :].reshape((1, -1))\n\n        if c == 0.5:\n            rate1 = 100\n            rate2 = 100\n        elif c == 0.2:\n            rate1 = 500\n            rate2 = 300\n        else:\n            print('wrong coherence level, accepted values are: 1, 0.5, 0.2')\n\n        # grow patch 1\n        for i_source in range(1, len(p1_locs)):\n            mean_coh = np.array([0, 1])\n            while (np.min(mean_coh) < c-0.2 or np.max(mean_coh) > c+0.2):\n                new_tc = fft(seed_tc[0, :].reshape((1, -1))) +\\\n                    np.random.randn(1, T)*(np.random.randn(1) * rate1+rate2)\n                new_tc = np.real(ifft(new_tc))*w1[i_source] *\\\n                    (np.linalg.norm(seed_tc[0, :]) /\n                     np.linalg.norm(np.real(ifft(new_tc))))\n\n                f, conn = signal.coherence(p1_tcs, new_tc, fs=fs, window='hann',\n                                           nperseg=nperseg, noverlap=nperseg//2,\n                                           nfft=nperseg, detrend='constant', axis=-1)\n\n                i_f_in = np.where((f >= fmin) & (f <= fmax))[0]\n                mean_coh = abs(conn[:, i_f_in]).mean(axis=-1).copy()\n\n            p1_tcs = np.append(p1_tcs, new_tc, axis=0)\n\n        # grow patch 2\n        for i_source in range(1, len(p2_locs)):\n            mean_coh = np.array([0, 1])\n            while (np.min(mean_coh) < c-0.2 or np.max(mean_coh) > c+0.2):\n                new_tc = fft(seed_tc[1, :].reshape((1, -1))) + \\\n                    np.random.randn(1, T)*(np.random.randn(1) * rate1+rate2)\n                new_tc = np.real(ifft(new_tc))*w2[i_source] *\\\n                    (np.linalg.norm(seed_tc[1, :]) /\n                     np.linalg.norm(np.real(ifft(new_tc))))\n                f, conn = signal.coherence(p2_tcs, new_tc, fs=fs, window='hann',\n                                           nperseg=nperseg, noverlap=nperseg//2,\n                                           nfft=nperseg, detrend='constant', axis=-1)\n\n                i_f_in = np.where((f >= fmin) & (f <= fmax))[0]\n                mean_coh = abs(conn[:, i_f_in]).mean(axis=-1).copy()\n\n            p2_tcs = np.append(p2_tcs, new_tc, axis=0)\n\n    p1_tcs_norm = np.linalg.norm(p1_tcs, ord='fro')\n    p2_tcs_norm = np.linalg.norm(p2_tcs, ord='fro')\n    return p1_tcs/p1_tcs_norm, p2_tcs/p2_tcs_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def err_X(Lambda, X, Y, G, GGt):\n    \"\"\"\n    Error in estimating X using the regularization parameter Lambda\n            _                       2\n    err_X = \\   ||X_Lambda(t)-X(t)||\n            /_t\n\n    Parameters:\n        Lambda: float (>0)\n            regularization parameter\n        X: array, shape (N_source, T)\n            activity of N_source sources\n        Y: array, shape (N_sensor, T)\n            Sensor level regordings\n        G: array, shape (N_sensor, N_source)\n            leadfiel matrix\n        GGt: array, shape (N_sensor, N_sensor)\n            GGt = G*G^T\n\n    Returns:\n        value: float\n            error\n    \"\"\"\n    T = X.shape[1]\n    if Lambda < 0:\n        value = np.inf\n    else:\n        I = np.eye(G.shape[0])\n        W_tik = G.T.dot(np.linalg.inv(GGt+Lambda*I))\n        value = (1/(T*G.shape[1]))*np.linalg.norm(W_tik.dot(Y)-X, ord='fro')**2\n    return value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def auc(Lambda, method, G, GGt, Y, p1_sources, p2_sources, fmin, fmax, PN_matrix,\n        fs, nperseg):\n    \"\"\"\n    Compute Area Under the Curve (AUC)\n\n    Parameters:\n        Lambda: float (>0)\n            regularization parameter\n        method: string | list/tuple of strings\n            connectivity metrics for which compute the AUC. Valid methods are\n            'cpsd', 'coh', 'cohy', 'imcoh', 'plv', 'ciplv', 'ppc', 'pli',\n            'pli2_unbiased', 'wpli', 'wpli2_debiased'\n        G: array, shape (N_sensor, N_source)\n            leadfiel matrix\n        GGt: array, shape (N_sensor, N_sensor)\n            GGt = G*G^T\n        Y: array, shape (N_sensor, T)\n            Sensor level recordings\n        p1_sources: array, list, tuple, shape (N_p1, )\n            indeces of the sources within patch 1\n        p2_sources: array, list, tuple, shape (N_p2, )\n            indeces of the sources within patch 2\n        fmin: float\n            minimum frequency for the computation of coherence\n        fmax: float\n            maximum frequency for the computation of coherence\n        PN_matrix: array, shape (N_p1, N_dense-N_p1)\n            matrix indicating which sources are connected (i.e. sources within\n            patch 1 with sources within patch 2)\n        fs: float\n            sampling frequency\n        nperseg: int\n            lenght of the epochs for the computation of the coherence\n\n    Returns:\n        AUC_value: float\n            Area under the curve\n        TPF_all: array, shape (number of connectivity metrics, 20)\n            True positive fraction for each connectivity metric and for each\n            threshold level\n        FPF_all: array, shape (number of connectivity metrics, 20)\n            False positive fraction for each connectivity metric and for each\n            threshold level\n    \"\"\"\n    if Lambda < 0:\n        value = 0\n    else:\n        if type(method) is str:\n            method = [method]\n        nfft = nperseg  # number of frequencies\n        M = G.shape[0]\n        N = G.shape[1]\n        T = Y.shape[1]\n        X_lam = G.T.dot(np.linalg.inv(GGt+Lambda*np.eye(M))).dot(Y)\n\n        Conn_lam = [np.zeros((len(p1_sources), N))]*len(method)\n\n        if 'cpsd' in method:\n            method_conn = method.copy()\n            method_conn.remove('cpsd')\n            conn_cpsd = np.zeros((len(p1_sources), N))\n            for k in range(len(p1_sources)):\n                f, Connlam_row = signal.csd(X_lam[p1_sources[k], :], X_lam,\n                                            fs=fs, window='hann', nperseg=nperseg,\n                                            noverlap=nperseg // 2, nfft=nfft,\n                                            detrend='constant', return_onesided=True,\n                                            scaling='density', axis=-1)\n                f_in = np.intersect1d(np.where(f >= fmin)[\n                                      0], np.where(f <= fmax)[0])\n                conn_cpsd[k, :] = np.mean(abs(Connlam_row[:, f_in]), axis=-1)\n            Conn_lam[method.index('cpsd')] = np.delete(\n                conn_cpsd, p1_sources, axis=-1)\n\n        else:\n            method_conn = method\n\n        if len(method_conn) > 0:\n            noverlap = nperseg//2\n            nepo = T//(nperseg-noverlap)-1\n            X_lam_re = np.zeros((nepo, N, nperseg))\n            for i_epo in range(nepo):\n                X_lam_re[i_epo, :, :] = X_lam[:,\n                                              (nperseg-noverlap)*i_epo:(nperseg-noverlap)*i_epo+nperseg]\n\n            indices = mne.connectivity.seed_target_indices(\n                p1_sources, np.arange(N))\n            (Conn, f, time, n_epochs, n_taper) = mne.connectivity.spectral_connectivity(\n                X_lam_re, method=method_conn, mode='fourier', indices=indices,\n                sfreq=fs, fmin=fmin, fmax=fmax, faverage=False, verbose=False)\n            for i_conn in range(len(method_conn)):\n                Conn_lam[method.index(method_conn[i_conn])] = \\\n                    np.reshape(abs(Conn[i_conn]).mean(\n                        axis=-1).copy(), (len(p1_sources), N))\n                Conn_lam[method.index(method_conn[i_conn])] = \\\n                    np.delete(Conn_lam[method.index(\n                        method_conn[i_conn])], p1_sources, axis=-1)\n\n        AUC_value = np.zeros((len(method)))\n        Alpha = np.linspace(np.finfo(float).eps, 1, 20)\n        Alpha = np.flip(Alpha)\n\n        TPF_all = np.zeros((len(method), len(Alpha)))\n        FPF_all = np.zeros((len(method), len(Alpha)))\n        for i_conn in range(len(method)):\n\n            TPF = np.zeros(len(Alpha))\n            FPF = np.zeros(len(Alpha))\n            for i_alp in range(len(Alpha)):\n                aux = np.where(abs(Conn_lam[i_conn]) >= Alpha[i_alp]*np.max(abs(Conn_lam[i_conn])),\n                               abs(Conn_lam[i_conn]), 0)\n                PN_evaluate = np.where(aux == 0, aux, 1)\n\n                TP = np.count_nonzero(PN_matrix == np.where(\n                    PN_evaluate == 1, PN_evaluate, -1))\n                FP = np.count_nonzero(PN_evaluate)-TP\n                FPF[i_alp] = FP/(PN_matrix.shape[0] *\n                                 PN_matrix.shape[1]-np.count_nonzero(PN_matrix))\n                TPF[i_alp] = TP/np.count_nonzero(PN_matrix)\n\n            TPF_all[i_conn, :] = TPF\n            FPF_all[i_conn, :] = FPF\n            AUC_value[i_conn] = -np.trapz(TPF, FPF)\n    return (AUC_value, TPF_all, FPF_all)\n\n\ndef spectral_complexity(X, fs, nperseg, fmin, fmax):\n    \"\"\"\n    Compute spectral complexity\n\n                          _                                 2\n    spectral_complexity = \\            ||power_spectrum(f)||\n                          /_fmin<f<fmax\n\n    Parameters:\n        X: array, shape (N_source, T)\n            brain activuty\n        fs: float\n            sampling frequency\n        nperseg: int\n            lenght of the epochs for the computation of the coherence\n        fmin: float\n            minimum frequency for the computation of coherence\n        fmax: float\n            maximum frequency for the computation of coherence\n        PN_matrix: array, shape (N_p1, N_dense-N_p1)\n            matrix indicating which sources are connected (i.e. sources within\n            patch 1 with sources within patch 2)\n\n    Returns:\n        sp_compl: float\n            spectral complexity\n    \"\"\"\n    nfft = nperseg\n    conn_cpsd = np.zeros((X.shape[0], X.shape[0]))\n    for k in range(X.shape[0]):\n        f, cpsd_row = signal.csd(X[k, :], X, fs=fs, window='hann',\n                                 nperseg=nperseg, noverlap=nperseg // 2,\n                                 nfft=nfft, detrend='constant',\n                                 return_onesided=True, scaling='density',\n                                 axis=-1)\n        f_in = np.intersect1d(np.where(f >= fmin)[0], np.where(f <= fmax)[0])\n        conn_cpsd[k, :] = np.std(abs(cpsd_row[:, f_in]), axis=-1)\n    sp_compl = np.triu(conn_cpsd).sum()/((X.shape[0]**2+X.shape[0])/2)\n    return sp_compl"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}